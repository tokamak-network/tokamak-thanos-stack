{{- if and .Values.kube-prometheus-stack.alertmanager.enabled .Values.thanosStack.namespace }}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ include "monitoring.fullname" . }}-thanos-stack-alerts
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "monitoring.labels" . | nindent 4 }}
    prometheus: kube-prometheus
    role: alert-rules
spec:
  groups:
  
  # ============================================================================
  # OP Stack Component Failures
  # ============================================================================
  - name: opstack.component.failures
    interval: 30s
    rules:
    
    - alert: OpNodeDown
      expr: up{job="op-node"} == 0
      for: 1m
      labels:
        severity: critical
        component: op-node
      annotations:
        summary: "OP Node is down"
        description: "OP Node ({{ $labels.instance }}) has been down for more than 1 minute. This will halt L2 block production."
        runbook_url: "https://docs.optimism.io/builders/node-operators/troubleshooting"

    - alert: OpBatcherDown
      expr: up{job="op-batcher"} == 0
      for: 2m
      labels:
        severity: critical
        component: op-batcher
      annotations:
        summary: "OP Batcher is down"
        description: "OP Batcher ({{ $labels.instance }}) has been down for more than 2 minutes. L2 transactions will not be submitted to L1."
        runbook_url: "https://docs.optimism.io/builders/node-operators/troubleshooting"

    - alert: OpProposerDown
      expr: up{job="op-proposer"} == 0
      for: 2m
      labels:
        severity: critical
        component: op-proposer
      annotations:
        summary: "OP Proposer is down"
        description: "OP Proposer ({{ $labels.instance }}) has been down for more than 2 minutes. L2 state roots will not be proposed to L1."
        runbook_url: "https://docs.optimism.io/builders/node-operators/troubleshooting"

    - alert: OpGethDown
      expr: up{job="op-geth"} == 0
      for: 1m
      labels:
        severity: critical
        component: op-geth
      annotations:
        summary: "OP Geth is down"
        description: "OP Geth ({{ $labels.instance }}) has been down for more than 1 minute. The L2 execution engine is not running."
        runbook_url: "https://docs.optimism.io/builders/node-operators/troubleshooting"

    - alert: OpGethSyncLag
      expr: |
        (
          op_geth_blockchain_head_block{job="op-geth"} - 
          op_geth_blockchain_head_block{job="op-geth"} offset 5m
        ) < 10
      for: 5m
      labels:
        severity: warning
        component: op-geth
      annotations:
        summary: "OP Geth sync is lagging"
        description: "OP Geth ({{ $labels.instance }}) has processed less than 10 blocks in the last 5 minutes. Sync may be stalled."

    - alert: OpNodeSyncLag
      expr: |
        (
          op_node_l2_block_height{job="op-node"} - 
          op_node_l2_block_height{job="op-node"} offset 5m
        ) < 5
      for: 5m
      labels:
        severity: warning
        component: op-node
      annotations:
        summary: "OP Node sync is lagging"
        description: "OP Node ({{ $labels.instance }}) has processed less than 5 blocks in the last 5 minutes."

  # ============================================================================
  # L1 RPC Connection Issues
  # ============================================================================
  - name: l1rpc.connectivity
    interval: 30s
    rules:
    
    - alert: L1RPCDown
      expr: probe_success{job="blackbox-eth-node-synced"} == 0
      for: 2m
      labels:
        severity: critical
        component: l1-rpc
      annotations:
        summary: "L1 RPC is unreachable"
        description: "L1 RPC endpoint ({{ $labels.instance }}) is not responding for more than 2 minutes. This will affect all OP Stack components."

    - alert: L1RPCHighLatency
      expr: probe_duration_seconds{job="blackbox-eth-node-synced"} > 5
      for: 3m
      labels:
        severity: warning
        component: l1-rpc
      annotations:
        summary: "L1 RPC high latency"
        description: "L1 RPC endpoint ({{ $labels.instance }}) response time is {{ $value }}s, which is above 5s threshold."

    - alert: L1BlockHeightLag
      expr: |
        (
          time() - on() eth_block_timestamp{job="blackbox-eth-block-number"}
        ) > 300
      for: 5m
      labels:
        severity: warning
        component: l1-rpc
      annotations:
        summary: "L1 block height is lagging"
        description: "L1 RPC ({{ $labels.instance }}) latest block is more than 5 minutes old. L1 may be experiencing issues."

  # ============================================================================
  # System Resource Thresholds
  # ============================================================================
  - name: system.resources
    interval: 1m
    rules:
    
    - alert: HighCPUUsage
      expr: |
        (
          rate(container_cpu_usage_seconds_total{namespace="{{ .Values.thanosStack.namespace }}"}[5m]) * 100
        ) > 90
      for: 5m
      labels:
        severity: warning
        component: system
      annotations:
        summary: "High CPU usage detected"
        description: "Container {{ $labels.container }} in pod {{ $labels.pod }} has CPU usage above 90% ({{ $value }}%) for more than 5 minutes."

    - alert: HighMemoryUsage
      expr: |
        (
          container_memory_usage_bytes{namespace="{{ .Values.thanosStack.namespace }}"} /
          container_spec_memory_limit_bytes{namespace="{{ .Values.thanosStack.namespace }}"} * 100
        ) > 90
      for: 5m
      labels:
        severity: warning
        component: system
      annotations:
        summary: "High memory usage detected"
        description: "Container {{ $labels.container }} in pod {{ $labels.pod }} has memory usage above 90% ({{ $value }}%) for more than 5 minutes."

    - alert: DiskSpaceHigh
      expr: |
        (
          100 - (
            node_filesystem_avail_bytes{mountpoint!~".*/(dev|proc|sys|var/lib/docker/.+)($|/.*)",fstype!="tmpfs"} /
            node_filesystem_size_bytes{mountpoint!~".*/(dev|proc|sys|var/lib/docker/.+)($|/.*)",fstype!="tmpfs"} * 100
          )
        ) > 85
      for: 10m
      labels:
        severity: warning
        component: system
      annotations:
        summary: "Disk space usage is high"
        description: "Filesystem {{ $labels.mountpoint }} on {{ $labels.instance }} has disk usage above 85% ({{ $value }}%)."

    - alert: PodCrashLooping
      expr: |
        rate(kube_pod_container_status_restarts_total{namespace="{{ .Values.thanosStack.namespace }}"}[15m]) > 0
      for: 5m
      labels:
        severity: critical
        component: system
      annotations:
        summary: "Pod is crash looping"
        description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is restarting frequently ({{ $value }} restarts in 15 minutes)."

    - alert: PodNotReady
      expr: |
        kube_pod_status_ready{condition="false", namespace="{{ .Values.thanosStack.namespace }}"} == 1
      for: 10m
      labels:
        severity: warning
        component: system
      annotations:
        summary: "Pod is not ready"
        description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has been not ready for more than 10 minutes."

  # ============================================================================
  # Blockchain Specific Metrics
  # ============================================================================
  - name: blockchain.specific
    interval: 1m
    rules:
    
    - alert: BlockProductionStalled
      expr: |
        (
          time() - op_geth_blockchain_head_block_timestamp{job="op-geth"}
        ) > 300
      for: 2m
      labels:
        severity: critical
        component: blockchain
      annotations:
        summary: "Block production has stalled"
        description: "No new blocks have been produced for more than 5 minutes. Latest block timestamp: {{ $value }}s ago."

    - alert: TransactionProcessingLag
      expr: |
        op_geth_txpool_pending{job="op-geth"} > 1000
      for: 10m
      labels:
        severity: warning
        component: blockchain
      annotations:
        summary: "High number of pending transactions"
        description: "Transaction pool has {{ $value }} pending transactions for more than 10 minutes, indicating processing lag."

    - alert: GasUsageHigh
      expr: |
        (
          op_geth_block_gas_used{job="op-geth"} /
          op_geth_block_gas_limit{job="op-geth"} * 100
        ) > 95
      for: 5m
      labels:
        severity: warning
        component: blockchain
      annotations:
        summary: "Block gas usage is very high"
        description: "Block gas usage is above 95% ({{ $value }}%) for more than 5 minutes, indicating network congestion."

    - alert: L2ToL1MessageQueueHigh
      expr: |
        op_node_l2_to_l1_message_queue_size{job="op-node"} > 100
      for: 15m
      labels:
        severity: warning
        component: blockchain
      annotations:
        summary: "L2 to L1 message queue is growing"
        description: "L2 to L1 message queue has {{ $value }} pending messages for more than 15 minutes."

    - alert: BatchSubmissionLag
      expr: |
        (
          time() - op_batcher_last_batch_submission_time{job="op-batcher"}
        ) > 3600
      for: 5m
      labels:
        severity: critical
        component: blockchain
      annotations:
        summary: "Batch submission to L1 is lagging"
        description: "No batches have been submitted to L1 for more than 1 hour ({{ $value }}s ago was the last submission)."

    - alert: StateRootProposalLag
      expr: |
        (
          time() - op_proposer_last_proposal_time{job="op-proposer"}
        ) > 7200
      for: 5m
      labels:
        severity: critical
        component: blockchain
      annotations:
        summary: "State root proposal to L1 is lagging"
        description: "No state roots have been proposed to L1 for more than 2 hours ({{ $value }}s ago was the last proposal)."

  # ============================================================================
  # Balance Monitoring
  # ============================================================================
  - name: component.balances
    interval: 5m
    rules:
    
    - alert: OpBatcherBalanceCritical
      expr: |
        op_batcher_default_balance{job="op-batcher"} < 0.01
      for: 1m
      labels:
        severity: critical
        component: op-batcher
      annotations:
        summary: "OP Batcher ETH balance is critically low"
        description: "OP Batcher ({{ $labels.instance }}) has only {{ $value }} ETH remaining. Immediate top-up required to maintain batch submission operations."

    - alert: OpProposerBalanceCritical
      expr: |
        op_proposer_default_balance{job="op-proposer"} < 0.01
      for: 1m
      labels:
        severity: critical
        component: op-proposer
      annotations:
        summary: "OP Proposer ETH balance is critically low"
        description: "OP Proposer ({{ $labels.instance }}) has only {{ $value }} ETH remaining. Immediate top-up required to maintain state root proposal operations."

{{- end }} 