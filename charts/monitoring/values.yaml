# Thanos Stack Monitoring Chart - Simplified Values
# Based on Legacy structure optimization (trh-sdk Integration)

# Global settings
global:
  # L1 RPC URL (will be set by Rollup Hub SDK)
  l1RpcUrl: ""
  
  # Storage configuration
  storage:
    # Enable persistent storage (dynamically set by trh-sdk)
    enabled: false
    # EFS filesystem ID (will be set by trh-sdk)
    efsFileSystemId: ""
  
  # Fargate-compatible security context (applied to all components)
  # Using grafana user (472) for EFS compatibility
  securityContext:
    runAsNonRoot: true
    runAsUser: 472
    runAsGroup: 472
    readOnlyRootFilesystem: false
    allowPrivilegeEscalation: false
  
  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 472
    runAsGroup: 472
    fsGroup: 472

# Chart behavior settings  
createNamespace: false  # Handled by Helm --create-namespace flag
nameOverride: ""
fullnameOverride: ""

# Service account settings
serviceAccount:
  create: true
  name: ""
  
# Thanos Stack specific configuration (set by trh-sdk)
thanosStack:
  # Chain name (will be set by trh-sdk)
  chainName: ""
  # Namespace where Thanos Stack is deployed (will be set by trh-sdk)
  namespace: ""
  # Thanos Stack chart release name (will be set by trh-sdk)
  releaseName: ""

# ============================================================================
# kube-prometheus-stack subchart configuration
# ============================================================================
kube-prometheus-stack:
  # Prometheus configuration (based on Legacy structure)
  prometheus:
    prometheusSpec:
      # Resource allocation (optimized for Thanos Stack)
      resources:
        requests:
          cpu: 1500m      # From Legacy config
          memory: 3Gi     # From Legacy config
        
      # Data retention settings
      retention: 1y
      retentionSize: 10GB
      
      # Scrape configuration
      scrapeInterval: 1m
      evaluationInterval: 1m
      
      # Storage configuration (will be set by trh-sdk via generated-values.yaml)
      # storageSpec will be added when global.storage.enabled=true
      
      # Thanos Stack scrape targets (trh-sdk format)
      additionalScrapeConfigs: []

  # Grafana configuration
  grafana:
    enabled: true
    
    # Admin credentials (will be set by trh-sdk)
    adminUser: admin
    adminPassword: ""  # Will be set by user input
    
    # Resource allocation
    resources:
      requests:
        cpu: 1500m
        memory: 4Gi
    
    # Storage configuration (will be set by trh-sdk via generated-values.yaml)
    # persistence will be added when global.storage.enabled=true
    
    # Ingress for ALB
    ingress:
      enabled: true
      ingressClassName: alb
      annotations:
        alb.ingress.kubernetes.io/scheme: internet-facing
        alb.ingress.kubernetes.io/target-type: ip
        alb.ingress.kubernetes.io/group.name: thanos-monitoring
    
    # Prometheus datasource configuration
    defaultDashboardsEnabled: false
    defaultDashboardsTimezone: utc
    
    # Dashboard providers
    sidecar:
      dashboards:
        enabled: true
        label: grafana_dashboard
        labelValue: "1"
        searchNamespace: ALL
      datasources:
        enabled: true
        defaultDatasourceEnabled: true

  # Alertmanager configuration
  alertmanager:
    enabled: true
    alertmanagerSpec:
      # Resource allocation
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        limits:
          cpu: 500m
          memory: 512Mi
      
      # Storage configuration (will be set by trh-sdk via generated-values.yaml)
      # storage will be added when global.storage.enabled=true
      
      # Configuration from Secret (managed by trh-sdk)
      configSecret: alertmanager-config
      
      # Data retention
      retention: 120h
      
      # Log level
      logLevel: info
  
  # Additional exporters (NodeExporter disabled for Fargate compatibility)
  nodeExporter:
    enabled: false  # Always disabled for Fargate compatibility
  
  kubeStateMetrics:
    enabled: true
  
  # Disable default PrometheusRules (only use thanos-stack-alerts)
  prometheusRule:
    enabled: false  # Disable default PrometheusRules
  
  # Disable all default rules to prevent conflicts
  defaultRules:
    enabled: false  # Disable all default rules

# ============================================================================
# prometheus-blackbox-exporter subchart configuration  
# ============================================================================
prometheus-blackbox-exporter:
  enabled: true
  
  # Blackbox Exporter configuration (optimized for trh-sdk)
  config:
    modules:
      # RPC sync status check (for L1 RPC)
      http_post_eth_node_synced_2xx:
        prober: http
        timeout: 10s
        http:
          method: "POST"
          headers:
            Content-Type: application/json
          body: '{"jsonrpc":"2.0","method":"eth_syncing","params":[],"id":1}'
          valid_status_codes: [200]
          preferred_ip_protocol: ip4
          fail_if_body_not_matches_regexp:
            - '"result"\s*:\s*false'
      # Block number check (for L1 RPC)
      http_post_eth_block_number_2xx:
        prober: http
        timeout: 10s
        http:
          method: "POST"
          headers:
            Content-Type: application/json
          body: '{"jsonrpc":"2.0","method":"eth_blockNumber","params":[],"id":83}'
          valid_status_codes: [200]
          preferred_ip_protocol: ip4
          fail_if_body_not_matches_regexp:
            - '"result"\s*:\s*"0x[0-9a-fA-F]+"'
      # TCP connectivity check (general purpose)
      tcp_connect:
        prober: tcp
        timeout: 5s
  
  # Resource allocation
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 256Mi
  
  # Service configuration
  service:
    type: ClusterIP
    port: 9115
  
  # ServiceMonitor for Prometheus discovery
  serviceMonitor:
    enabled: true
    defaults:
      labels:
        app: blackbox-exporter
      interval: 30s
      scrapeTimeout: 30s

# ============================================================================
# Thanos Stack Integration
# ============================================================================

# Specific scrape targets
scrapeTargets:
  opNode:
    enabled: true
    port: 7300
    path: "/metrics"
    interval: "30s"
  opBatcher:
    enabled: true
    port: 7300
    path: "/metrics"
    interval: "30s"
  opProposer:
    enabled: true
    port: 7300
    path: "/metrics"
    interval: "30s"
  opGeth:
    enabled: true
    port: 6060
    path: "/debug/metrics/prometheus"
    interval: "30s"
  blockscout:
    enabled: true
    port: 3000
    path: "/metrics"
    interval: "1m"
  blockExplorerFrontend:
    enabled: true
    port: 80
    path: "/api/healthz"
    interval: "1m"

# Additional scrape configurations (for custom targets)
additionalScrapeConfigs: []

# ============================================================================
# AlertManager Configuration (User Input)
# ============================================================================
# AlertManager configuration can be set by user input
# If not provided, trh-sdk will prompt for these values during installation

alertManager:
  # Telegram Configuration
  telegram:
    # Enable Telegram notifications
    enabled: false
    # Telegram Bot API Token (get from @BotFather)
    apiToken: ""
    # Telegram Chat IDs (comma-separated for multiple chats)
    chatIds: []
    # Example: ["123456789", "987654321"]
  
  # Email Configuration
  email:
    # Enable Email notifications
    enabled: false
    # SMTP Server (e.g., smtp.gmail.com:587)
    smtpServer: ""
    # From Email Address
    smtpFrom: ""
    # SMTP Username
    smtpUsername: ""
    # SMTP Password (use app password for Gmail)
    smtpPassword: ""
    # Email Receivers (comma-separated)
    receivers: []
    # Example: ["admin@example.com", "ops@example.com"]
  
  # Alert Routing Configuration
  routing:
    # Default receiver for all alerts
    defaultReceiver: "telegram-critical"
    # Group by settings
    groupBy: ["alertname", "cluster", "service", "severity"]
    # Timing settings
    groupWait: "30s"
    groupInterval: "5m"
    repeatInterval: "4h"

# ============================================================================
# Legacy AlertManager Configuration (Managed by trh-sdk)
# ============================================================================
# AlertManager configuration is now dynamically generated by trh-sdk
# and applied as a Kubernetes Secret (alertmanager-config)
# Configuration includes:
# - Telegram notifications (from user input)
# - Email notifications (from user input)
# - Alert routing and inhibition rules

loki:
  enabled: true
  persistence:
    enabled: true
    storageClass: efs-sc
    size: 50Gi
  config:
    table_manager:
      retention_deletes_enabled: true
      retention_period: 30d

promtail:
  enabled: true
  persistence:
    enabled: true
    storageClass: efs-sc
    size: 5Gi
  config:
    clients:
      - url: http://loki:3100/loki/api/v1/push
    positions:
      filename: /data/promtail-positions.yaml
    scrape_configs:
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_loki_grafana_com_scrape]
            action: keep
            regex: "true"
          - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
            target_label: app

# Grafana Loki datasource 자동 등록
# (grafana subchart가 있다면 grafana.datasources로, 없다면 별도 안내)
grafana:
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Loki
          type: loki
          access: proxy
          url: http://loki:3100

